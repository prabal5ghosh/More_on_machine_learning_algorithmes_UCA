{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfp1U9PMeQU1"
   },
   "source": [
    "\n",
    "# TP CNN interpretation: CAM and Guided Grad-CAM\n",
    "### Diane LINGRAND \n",
    "\n",
    "diane.lingrand@univ-cotedazur.fr   \n",
    "Octobre 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uo8ucmMpgEp9"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:09:59.685222Z",
     "start_time": "2023-03-12T21:09:45.577954Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "68uwyRRi4BMK"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import tensorflow \n",
    "print(tensorflow.__version__)\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Activation\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMrLWuFy9gn7"
   },
   "source": [
    "**The GPU**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TO0xCfDwz-zT"
   },
   "source": [
    "To enable GPU backend in Google colab for your notebook:\n",
    "\n",
    "1.   Runtime (top left corner) -> Change runtime type\n",
    "2.   Put GPU as \"Hardware accelerator\"\n",
    "3.   Save.\n",
    "\n",
    "Or run the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T16:01:19.986158Z",
     "start_time": "2021-11-27T16:01:19.712649Z"
    }
   },
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bfCDrvt8qQPY"
   },
   "source": [
    "### Loading the dataset\n",
    "In this part, we will use photographies of animals from the kaggle dataset [animals-10](https://www.kaggle.com/alessiocorrado99/animals10). Please connect to their site before loading the dataset from this [zip file](http://www.i3s.unice.fr/~lingrand/raw-img.zip). Decompress the zip file on your disk.\n",
    "\n",
    "If you are using google colab, there is no need to download the dataset because I have a copy on my drive. You just need add to your drive this shared folder: https://drive.google.com/drive/folders/15cB1Ky-7OTUqfcQDZZyzc5HArt0GA6Sm?usp=sharing\n",
    "You need to click on the link and click on \"Add shortcut to Drive\" and then select \"My Drive\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:10:00.027833Z",
     "start_time": "2023-03-12T21:09:59.693499Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "i_yPS5rYF1Sk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, MaxPooling2D, Flatten\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, f1_score\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import glob\n",
    "# when processing time is long, it's nice to see the progress bar\n",
    "#!pip install tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IzHkKLqlZPn3"
   },
   "source": [
    "### loading train data\n",
    "\n",
    "Please read the code before running any of the cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:10:02.576382Z",
     "start_time": "2023-03-12T21:10:00.037698Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xkVd3v4N3LnB"
   },
   "outputs": [],
   "source": [
    "datasetRoot='/home/lingrand/Ens/MachineLearning/animals/raw-img/'\n",
    "#datasetRoot='/whereYouPutTheImages/'\n",
    "#datasetRoot='/content/drive/My Drive/raw-img/'\n",
    "# I suggest to reduce the number of classes for a first trial. \n",
    "# If you finish this notebook before the end of the course, you can add more classes (and images per class).\n",
    "classes = ['mucca', 'elefante', 'gatto'] #, 'cavallo', 'scoiattolo', 'ragno', 'pecora', 'farfalla', 'gallina', 'cane']\n",
    "nbClasses = len(classes)\n",
    "\n",
    "#training data\n",
    "\n",
    "rootTrain = datasetRoot+'train/'\n",
    "classLabel = 0\n",
    "reducedSizePerClass = 200 #in order to reduce the number of images per class\n",
    "totalImg = nbClasses * reducedSizePerClass\n",
    "xTrain = np.empty(shape=(totalImg,224,224,3))\n",
    "yTrain = []\n",
    "first = True\n",
    "i= 0\n",
    "for cl in classes:\n",
    "    listImages = glob.glob(rootTrain+cl+'/*')\n",
    "    yTrain += [classLabel]*reducedSizePerClass #len(listImages) # note that here ...\n",
    "    for pathImg in tqdm(listImages[:reducedSizePerClass]): # and here, we have reduced the data to be loaded (only 1000 per class)\n",
    "        img = image.load_img(pathImg, target_size=(224,224))\n",
    "        im = image.img_to_array(img)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        im = preprocess_input(im)\n",
    "        xTrain[i,:,:,:] = im\n",
    "        i += 1\n",
    "    classLabel += 1\n",
    "print(len(yTrain))\n",
    "print(xTrain.shape)\n",
    "yTrain = tensorflow.keras.utils.to_categorical(yTrain, nbClasses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "56bq9oXanGUm"
   },
   "source": [
    "In order to speed-up the time spent on this part of the lab, you may have noticed that we reduced the number of classes and the number of images per class. You can change these few lines of code if you want to work on the whole dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "boNapUgGaEMj"
   },
   "source": [
    "### loading test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:10:07.434575Z",
     "start_time": "2023-03-12T21:10:02.603415Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Zwi5TBlKajtt"
   },
   "outputs": [],
   "source": [
    "#you need to use the same classes for the test dataset than for the train dataset\n",
    "rootTest = datasetRoot+'test/'\n",
    "classLabel = 0\n",
    "\n",
    "totalTestImg = 0\n",
    "for cl in classes:\n",
    "    totalTestImg += len(glob.glob(rootTest+cl+'/*'))\n",
    "\n",
    "print(\"There are \",totalTestImg, \" images in test dataset.\")\n",
    "xTest = np.empty(shape=(totalTestImg,224,224,3))\n",
    "yTest = []\n",
    "i = 0\n",
    "\n",
    "for cl in classes:\n",
    "    listImages = glob.glob(rootTest+cl+'/*')\n",
    "    yTest += [classLabel]*len(listImages)\n",
    "    for pathImg in listImages:\n",
    "        img = image.load_img(pathImg, target_size=(224, 224))\n",
    "        im = image.img_to_array(img)\n",
    "        im = np.expand_dims(im, axis=0)\n",
    "        im = preprocess_input(im)\n",
    "        if(np.max(im)==0):\n",
    "            print('n')\n",
    "        xTest[i,:,:,:] = im.copy()\n",
    "        if(np.max(xTest[i])==0):\n",
    "            print('m')\n",
    "        i+=1\n",
    "    classLabel += 1\n",
    "print(len(yTest))\n",
    "\n",
    "yTest = tensorflow.keras.utils.to_categorical(yTest, nbClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:10:47.048502Z",
     "start_time": "2023-03-12T21:10:46.837017Z"
    }
   },
   "outputs": [],
   "source": [
    "i=135\n",
    "img = image.load_img(listImages[i], target_size=(224, 224))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAM Class Activation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T10:39:54.981220Z",
     "start_time": "2021-12-08T10:39:53.234615Z"
    }
   },
   "outputs": [],
   "source": [
    "VGGmodel = VGG16(weights='imagenet', include_top=False)\n",
    "# we will add layers to this feature extraction part of VGG network\n",
    "m = VGGmodel.output\n",
    "# we start with a global average pooling\n",
    "m = # your code\n",
    "# finally, the softmax layer for predictions (we have nbClasses classes)\n",
    "predictions = #layer (m)\n",
    "\n",
    "# global network\n",
    "model = Model(inputs=VGGmodel.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T16:28:33.691661Z",
     "start_time": "2021-12-08T16:28:33.682125Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T10:39:56.616796Z",
     "start_time": "2021-12-08T10:39:56.613236Z"
    }
   },
   "outputs": [],
   "source": [
    "ourCallback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=20, verbose=0, mode='auto', baseline=None, restore_best_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T12:57:10.170573Z",
     "start_time": "2021-12-08T11:44:20.194441Z"
    }
   },
   "outputs": [],
   "source": [
    "# training part I: training only the classification part (the end)\n",
    "for layer in VGGmodel.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(xTrain, yTrain, epochs=2000, batch_size=128, validation_split=0.2, callbacks=[ourCallback],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T16:28:48.500585Z",
     "start_time": "2021-12-08T16:28:48.493592Z"
    }
   },
   "outputs": [],
   "source": [
    "# RECOVER THE WEIGHTS OF THE LAST LAYER\n",
    "layer = model.get_layer(#the name of the last dense layer)\n",
    "w = layer.get_weights()\n",
    "print(\"number of weights: \", len(w))\n",
    "w2 = w[0]\n",
    "print(w2.shape)\n",
    "# IS IT CORRECT ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T16:31:20.335270Z",
     "start_time": "2021-12-08T16:28:58.721525Z"
    }
   },
   "outputs": [],
   "source": [
    "# COMPUTE THE FEATURES MAPS FOR xTest\n",
    "allFeatures = ###.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T16:33:46.349573Z",
     "start_time": "2021-12-08T16:31:20.619027Z"
    }
   },
   "outputs": [],
   "source": [
    "# PREDICT THE CLASSES FOR xTest\n",
    "predClasses = ###.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T16:45:07.504823Z",
     "start_time": "2021-12-08T16:45:07.498634Z"
    }
   },
   "outputs": [],
   "source": [
    "xTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T15:52:28.055736Z",
     "start_time": "2022-03-14T15:52:28.041448Z"
    }
   },
   "outputs": [],
   "source": [
    "index = # choose one index for one test image\n",
    "maps = allFeatures[index]\n",
    "print(\"dim of maps = \", maps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T16:45:15.262057Z",
     "start_time": "2021-12-08T16:45:15.248451Z"
    }
   },
   "outputs": [],
   "source": [
    "#predicted class\n",
    "cl = np.argmax(predClasses[index])\n",
    "print(\"class = \", cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T16:45:15.844307Z",
     "start_time": "2021-12-08T16:45:15.837037Z"
    }
   },
   "outputs": [],
   "source": [
    "we = ## extract the weights associated to the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T16:45:16.617567Z",
     "start_time": "2021-12-08T16:45:16.598090Z"
    }
   },
   "outputs": [],
   "source": [
    "# COMPUTE THE CAM map\n",
    "cam = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale values of the cam map\n",
    "leMin = np.min(cam)\n",
    "leMax = np.max(cam)\n",
    "camimg = (cam-leMin)/(leMax-leMin)\n",
    "plt.imshow(cam, cmap = plt.cm.gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T16:45:21.466322Z",
     "start_time": "2021-12-08T16:45:21.300944Z"
    }
   },
   "outputs": [],
   "source": [
    "# display the image in grey levels\n",
    "plt.imshow(0.5*image[:,:,1],cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T16:45:21.585214Z",
     "start_time": "2021-12-08T16:45:21.582805Z"
    }
   },
   "outputs": [],
   "source": [
    "print(image[:,:,1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# and add the rescaled cam map with false colors and transparency\n",
    "from skimage.transform import resize\n",
    "plt.imshow(resize(camimg, (224,224)))\n",
    "plt.imshow(image[:,:,1],cmap=plt.cm.gray, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:35:24.095262Z",
     "start_time": "2023-03-12T21:35:24.092517Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T21:36:00.614239Z",
     "start_time": "2023-03-12T21:36:00.417379Z"
    }
   },
   "outputs": [],
   "source": [
    "# example of gradient tape\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    output, predictions = model(np.array([img]))\n",
    "    c = np.argmax(predictions)\n",
    "    print(\"class = \", c)\n",
    "    loss = predictions[:, cl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-12T22:12:33.183728Z",
     "start_time": "2023-03-12T22:12:32.970880Z"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "plt.imshow(resize(gradcamimg, (224,224)))\n",
    "plt.colorbar()\n",
    "plt.imshow(image[:,:,1],cmap=plt.cm.gray, alpha=0.4)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ImageClassificationUsingDeepLearning.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "121.85px",
    "left": "491.667px",
    "right": "20px",
    "top": "120px",
    "width": "341.667px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
